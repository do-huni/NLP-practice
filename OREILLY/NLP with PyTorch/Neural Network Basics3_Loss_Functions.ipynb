{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPi64bySEvjYLd6HUSAg+Em",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/do-huni/NLP_practice/blob/main/OREILLY/NLP%20with%20PyTorch/Neural%20Network%20Basics3_Loss_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ueqQq4xhwhVR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**mean squared error(MSE)**\n",
        "\n",
        "---\n",
        "출력과 타깃이 연속값인 **회귀 문제**에 주로 사용. 예측과 타깃값 차이(error)를 제곱(square)해서 평균(mean)낸 값."
      ],
      "metadata": {
        "id": "5nTbr6Bc0iNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_loss = nn.MSELoss()\n",
        "Hx = torch.randn(3,5,requires_grad =True)\n",
        "targets = torch.randn(3,5)\n",
        "loss = mse_loss(Hx, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3IJ6q2JwtoQ",
        "outputId": "00c09a71-3352-4c67-8fcd-940162bffba5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.4366, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**categorical cross-entropy error(CCE)**\n",
        "\n",
        "---\n",
        "출력을 클래스 소속 확률에 대한 예측으로 이해할 수 있는 **다중 분류 문제**에 사용. 타깃 값은 모든 클래스에 대한 다항 분포를 나타내는 원소 n개로 구성된 벡터. 만약 정답이 하나의 클래스일 경우 원-핫 벡터의 형태. 출력 값은 n개의 원소를 가진 벡터이며 두 벡터를 비교해 손실을 계산함.\n",
        "\n",
        "파이토치에서 cross-entropy error는 softmax와 합쳐져서 간략화된 꼴로 구현한다. 그 이유는 4가지 계산 제약 사항에 기인한다.\n",
        "1. cross-entropy는 수의 범위 제한이 있다.\n",
        "2. softmax에 사용한 지수 함수의 입력이 음수이면 그 결과는 기하급수적으로 작아지고, 양수이면 기하급수적으로 큰 수가 된다.\n",
        "3. 신경망의 출력은 softmax 함수를 적용하기 직전의 벡터라고 가정한다.\n",
        "4. 로그 함수는 지수 함수의 역함수이고, log(exp(x))는 x와 같다.\n",
        "\n",
        "cross-entropy와의 계산을 간소화하기 위해 softmax함수에 로그를 취해 로그 확률을 계산한다.(-> LogSoftmax() 클래스)\n",
        "\n",
        "로그 확률을 얻고 난 후에 cross-entropy loss 계산은 타깃 * 로그 확률의 꼴로 간략화 된다.(-> NLLoss() 클래스)\n",
        "\n",
        "이 두 클래스를 합쳐 놓은 것이 CrossEntropyLoss() 클래스이다."
      ],
      "metadata": {
        "id": "JNjhCjGlz-9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ce_loss = nn.CrossEntropyLoss()\n",
        "Hx = torch.randn(3,5, requires_grad = True)\n",
        "targets = torch.tensor([1,0,3], dtype = torch.int64)\n",
        "loss = ce_loss(Hx, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHCDh3w3xPB_",
        "outputId": "e22c24b5-b785-4ac4-95a7-d2bf0d1b2d11"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3367, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**binary cross-entropy error(BCE)**\n",
        "---\n",
        "**이진 분류(binary classification)**에서 사용하는 cross-entropy 손실 함수."
      ],
      "metadata": {
        "id": "IaW0w7j25fNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bce_loss = nn.BCELoss()\n",
        "sigmoid = nn.Sigmoid()\n",
        "probabilities = sigmoid(torch.randn(4,1, requires_grad = True))\n",
        "targets = torch.tensor([1,0,1,0], dtype = torch.float32).view(4,1)\n",
        "loss = bce_loss(probabilities, targets)\n",
        "print(probabilities)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQtrMtTH6DWo",
        "outputId": "fa12acee-eab7-439c-d30f-1dfae8762ee9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4505],\n",
            "        [0.7553],\n",
            "        [0.3400],\n",
            "        [0.5497]], grad_fn=<SigmoidBackward0>)\n",
            "tensor(1.0205, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    }
  ]
}